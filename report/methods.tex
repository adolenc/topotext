\section{Methods} 
\label{sec:methods}

With each document being a single point in space, we can now construct
topological complex on top of multiple points and check its persistence
diagrams. In order to obtain some meaningful data out of it, we first
(randomly) split 20 documents from each domain onto train and test sets with 10
documents per set. We then constructed a complex of dimension $\le 2$ for each
of these 6 sets (3 domains, each containing train and test sets), resulting in
6 complexes. After this we used clustering (either single-linkage or
max-linkage) on persistence diagrams of these complexes using bottleneck
distance as the distance metric. If the persistence diagrams did in fact differ
between domains, we would optimally obtain 3 clusters where only persistence
diagrams of train and test sets from same domain would be connected.

Our original intention was to use alpha shapes as our complexes, however since
we were unable to find an implementation of alpha shapes for points in more
than $3$ dimensions, we had to resort to first reducing the dimensions of our
datasets. We achieved this using principal component analysis (\textit{PCA}),
which reduced number of columns in each train and test set down to just 3,
enabling us to use 3 dimensional alpha shapes without any modifications. Since
we feared that using PCA would negatively affect our result, we also tried
building other complexes on whole dataset; i.e.\ we constructed Vietoris-Rips
complex and Čech complex instead of alpha shapes. Since our favorite library
for computational topology Dionysus doesn't come with a nice python wrapper for
Čech complex, we had to write that ourselves.

\todo{describe splitting interval $[0,R]$ to 10 parts}
